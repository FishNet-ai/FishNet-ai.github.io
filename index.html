<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="DESCRIPTION META TAG">
    <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
    <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
    <meta property="og:url" content="URL OF THE WEBSITE"/>
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="630"/>


    <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
    <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
    <meta name="twitter:card" content="summary_large_image">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>FishNet</title>
    <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
</head>
<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">FishNet: A Large-scale Dataset and Benchmark  for Fish Recognition, Detection, and Functional Traits Prediction
                        Generation</h1>
                    <div class="is-size-5 publication-authors">
                        <!-- Paper authors -->
                        <!--              <span class="author-block">-->
                        <!--                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">First Author</a><sup>*</sup>,</span>-->
                        <!--                <span class="author-block">-->
                        <!--                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Second Author</a><sup>*</sup>,</span>-->
                        <!--                  <span class="author-block">-->
                        <!--                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Third Author</a>-->
                        <!--                  </span>-->
                    </div>

                    <!--                  <div class="is-size-5 publication-authors">-->
                    <!--                    <span class="author-block">Institution Name<br>Conferance name and year</span>-->
                    <!--                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>-->
                    <!--                  </div>-->
                    <div class="is-size-5 publication-authors">
                        <span class="author-block">Anonymous Submission</span>
                    </div>


                    <div class="column has-text-centered">
                        <!--                    <div class="publication-links">-->
                        <!--                         &lt;!&ndash; Arxiv PDF link &ndash;&gt;-->
                        <!--                      <span class="link-block">-->
                        <!--                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"-->
                        <!--                        class="external-link button is-normal is-rounded is-dark">-->
                        <!--                        <span class="icon">-->
                        <!--                          <i class="fas fa-file-pdf"></i>-->
                        <!--                        </span>-->
                        <!--                        <span>Paper</span>-->
                        <!--                      </a>-->
                        <!--                    </span>-->

                        <!-- Supplementary PDF link -->
                        <!--                    <span class="link-block">-->
                        <!--                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"-->
                        <!--                      class="external-link button is-normal is-rounded is-dark">-->
                        <!--                      <span class="icon">-->
                        <!--                        <i class="fas fa-file-pdf"></i>-->
                        <!--                      </span>-->
                        <!--                      <span>Supplementary</span>-->
                        <!--                    </a>-->
                        <!--                  </span>-->

                        <!-- Github link -->
                        <!-- <span class="link-block">
                    <a href="https://github.com/EmoTalker/EmoTalker" target="_blank"
                       class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a> -->
                </span>

                        <!-- ArXiv abstract Link -->
                        <!--                <span class="link-block">-->
                        <!--                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"-->
                        <!--                  class="external-link button is-normal is-rounded is-dark">-->
                        <!--                  <span class="icon">-->
                        <!--                    <i class="ai ai-arxiv"></i>-->
                        <!--                  </span>-->
                        <!--                  <span>arXiv</span>-->
                        <!--                </a>-->
                        <!--              </span>-->
                    </div>
                </div>
            </div>
        </div>
    </div>
    </div>
</section>


<!-- Teaser video--> 
 <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
            <img src="static/images/teaser.png" alt="teaser" width="100%">
            <p><i>We present FishNet, a comprehensive benchmark for large-scale aquatic species recognition, detection, and functional trait identification. 
                Our benchmark dataset is based on an aquatic biological taxonomy, consisting of 8 taxonomic classes, 83 orders, 463 families, 3,826 genera, 17,357 species, and 94,532 images (each species is represented by at least one image).
                The dataset also includes bounding box annotations for fish detection. Additionally, the dataset encompasses 22 functional traits, grouped into three categories: habitat, ecological rule, and nutritional value. 
                These functional traits facilitate the identification of the ecological roles of aquatic species and their interactions with other species.</i></p>
    </div>
  </div>
</section> 
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        Aquatic species are essential components of the world's ecosystem, and the preservation of aquatic biodiversity is crucial for maintaining proper ecosystem functioning. 
                        Unfortunately, increasing anthropogenic pressures such as overfishing, climate change, and coastal development pose significant threats to aquatic biodiversity. 
                        To address this challenge, it is necessary to design an automatic aquatic species monitoring system that can help researchers and policymakers better understand changes in aquatic ecosystems and
                        take appropriate actions to preserve biodiversity.
                        
                        However, the development of such a system is impeded by a lack of large-scale diverse aquatic species datasets.
                        Existing aquatic species recognition datasets generally have a limited number of species and do not provide functional traits, thus cannot meets the need for aquatic ecology study. 
                        To address the need for systems that can recognize, locate, and predict species and their functional traits, we present FishNet, a large-scale diverse dataset containing 94,532 meticulously organized images from 17,357 aquatic species, organized according to aquatic biological taxonomy (order, family, genus, and species). 
                        We further build three benchmarks, i.e., fish classification, fish detection, and functional traits prediction, inspired by ecological research needs, to facilitate the development of aquatic species recognition systems, and promote further research in the field of aquatic ecology. 
                        Our FishNet dataset has the potential to encourage the development of more accurate and effective tools for the monitoring and protection of aquatic ecosystems, and hence take effective action toward the conservation of our planet's aquatic biodiversity. Our dataset and code will be made publicly available.

                </div>
            </div>
        </div>
    </div>
</section>
<!-- End paper abstract -->
<br>
<section class="hero teaser">
    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
            <h2 class="title is-3">Comparison with other datasets</h2>
            <!-- <h4 class="title is-5">Input: Neutral identity image + Audio</h4> -->
            <div style="text-align: center;">
                <table align="center" border="4px solid black" width="60%" min-width="300px" caption-side="left">
                    <caption>Comparison with existing datasets for fish recognition. FishNet provides annotations following biological taxonomy from class(5) to
                        species(1); while previous datasets only provide species-level annotations. FishNet covers two orders of magnitude more species categories
                        than existing datasets (17k vs 130). More importantly, FishNet provides additional functional traits that enable trait identification.</caption>
                    <tr>
                        <th rowspan="2">Datasets</th>
                        <th colspan="4">Properties</th>
                        <th colspan="3">Tasks</th>
                        </tr>
                        <tr>
                            <td >Images</td>
                            <td>Species</td>
                            <td>Taxonomy Level</td>
                            <td>Functional Traits</td>
                            <td>Classification</td>
                            <td>Traits Prediction</td>
                            <td>Detection</td>
                        </tr>
                        <tr>
                            <td>Fish4-Knowledge-A</td>
                            <td>27,370</td>
                            <td>23</td>
                            <td>1</td>
                            <td>x</td>
                            <td>✓</td>
                            <td>x</td>
                            <td>x</td>
                        </tr>
                        <tr>
                            <td>SEAMPD-21</td>
                            <td>28,328</td>
                            <td>130</td>
                            <td>1</td>
                            <td>x</td>
                            <td>✓</td>
                            <td>x</td>
                            <td>x</td>
                        </tr>
                        <tr>
                            <td>Fish-gres</td>
                            <td>3,248</td>
                            <td>8</td>
                            <td>1</td>
                            <td>x</td>
                            <td>✓</td>
                            <td>x</td>
                            <td>x</td>
                        </tr>
                        <tr>
                            <td>Mediterranean Fish Species</td>
                            <td>~40,000</td>
                            <td>20</td>
                            <td>1</td>
                            <td>x</td>
                            <td>✓</td>
                            <td>x</td>
                            <td>x</td>
                        </tr>
                        <tr>
                            <td>Fish Abundance</td>
                            <td>4,909</td>
                            <td>50</td>
                            <td>1</td>
                            <td>x</td>
                            <td>✓</td>
                            <td>x</td>
                            <td>x</td>
                        </tr>
                        <tr>
                            <td>Image Dataset</td>
                            <td>33,805</td>
                            <td>30</td>
                            <td>1</td>
                            <td>x</td>
                            <td>✓</td>
                            <td>x</td>
                            <td>x</td>
                        </tr>
                        <tr>
                            <td>NCFM</td>
                            <td>16,915</td>
                            <td>8</td>
                            <td>1</td>
                            <td>x</td>
                            <td>✓</td>
                            <td>x</td>
                            <td>x</td>
                        </tr>
                        <tr>
                            <td><b>Ours</b></td>
                            <td>94,778</td>
                            <td>17,357</td>
                            <td>5-1</td>
                            <td>✓</td>
                            <td>✓</td>
                            <td>✓</td>
                            <td>✓</td>
                        </tr>
                </table>
            </div>
            <br>
            <br>
        </div>
    </div>
</section>

<!-- Paper motivation -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Motivation</h2>
                <div class="content has-text-justified">
                    <p>
                        Aquatic biodiversity is of paramount importance in safeguarding the structure, stability, and overall health of aquatic ecosystems. Nonetheless, in recent decades, the escalating anthropogenic pressures 
                        from human activities, including fisheries, climate change, and coastal development, have made the conservation of aquatic biodiversity increasingly difficult and 
                        increasingly prominent in public attention. A key step in aquatic biodiversity protection is the ongoing monitoring, which calls for highly efficient species recognition and functional traits identification. 
                        However, this process generally calls for a high level of expert knowledge due to complicated species taxonomy, which makes it time- and labor-consuming. 
                    </p>
                    <p>
                        In recent years, deep learning methods have made significant breakthroughs in various computer vision tasks, presenting a promising solution for automatic and efficient species recognition. 
                        However, it is well-known that the accuracy of these AI-based models is heavily reliant on the scale and diversity of the training datasets. In the context of safeguarding aquatic biodiversity, 
                        there is an urgent need to develop large-scale and diverse datasets to facilitate AI-based aquatic species recognition systems. Several previous works have focused on building such datasets for fish 
                        recognition. For example, Fish4Knowledge collected 27,370 fish images from 23 distinct species. In another study, 33,805 images of 30 different fish species from Barcelona, 
                        Spain were collected for this purpose. Other works have also accumulated fish images from specific regions, primarily focusing on species 
                        classification. However, these datasets are limited to a small number of species, posing a challenge to their application in real-world scenarios that require the recognition of diverse species. 
                        Therefore, there is an urgent need to develop more extensive and diverse datasets that can enable more robust AI-based systems to accurately identify a broader range of aquatic species, supporting aquatic
                         biodiversity conservation efforts.
                        </p>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End paper motivation -->

<br>
<!-- Paper Results -->
<section class="hero teaser">
    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
            <h2 class="title is-3">Classification Results</h2>
            <!-- <h4 class="title is-5">Input: Neutral identity image + Audio</h4> -->
            <div style="text-align: center;">
                <table align="center" border="4px solid black" width="60%" min-width="300px" caption-side="left">
                    <caption>Fish Family/Order classification accuracy. * denotes training from scratch, `FL' denotes using focal loss during training, and `CB' denotes using class balanced training.</caption>
                    <tr>
                        <th rowspan="2">Backbone</th>
                        <th colspan="4">Family Classification %</th>
                        <th colspan="4">Order Classification %</th>
                        </tr>
                        <tr>
                            <td >Common</td>
                            <td>Medium</td>
                            <td>Rare</td>
                            <td>All</td>
                            <td >Common</td>
                            <td>Medium</td>
                            <td>Rare</td>
                            <td>All</td>
                        </tr>
                        <tr>
                            <td>ResNet-34</td>
                            <td>77.16</td>
                            <td>69.10</td>
                            <td>36.65</td>
                            <td>40.82</td>
                            <td>83.42</td>
                            <td>77.87</td>
                            <td>47.36</td>
                            <td>52.07</td>
                        </tr>
                        <tr>
                            <td>ResNet-50</td>
                            <td>76.82</td>
                            <td>70.27</td>
                            <td>35.99</td>
                            <td>40.37</td>
                            <td>82.46</td>
                            <td>75.93</td>
                            <td>42.84</td>
                            <td>47.94</td>
                        </tr>
                        <tr>
                            <td>ResNet-101</td>
                            <td>75.73</td>
                            <td>69.00</td>
                            <td>31.61</td>
                            <td>36.38</td>
                            <td>81.35</td>
                            <td>75.01</td>
                            <td>42.32</td>
                            <td>47.36</td>
                        </tr>
                        <tr>
                            <td>ViT-S</td>
                            <td>76.08</td>
                            <td>67.02</td>
                            <td>33.67</td>
                            <td>37.97</td>
                            <td>84.14</td>
                            <td>74.78</td>
                            <td>44.09</td>
                            <td>48.79</td>
                        </tr>
                        <tr>
                            <td>ViT-B</td>
                            <td>82.93</td>
                            <td>74.50</td>
                            <td>38.26</td>
                            <td>42.91</td>
                            <td>88.52</td>
                            <td>81.64</td>
                            <td>52.44</td>
                            <td>56.93</td>
                        </tr>
                        <tr>
                            <td>ViT-L</td>
                            <td>85.51</td>
                            <td>77.05</td>
                            <td>44.18</td>
                            <td>48.40</td>
                            <td>89.02</td>
                            <td>83.89</td>
                            <td>55.94</td>
                            <td>60.26</td>
                        </tr>
                        <tr>
                            <td>BeiT</td>
                            <td>86.09</td>
                            <td>77.67</td>
                            <td>50.78</td>
                            <td>54.26</td>
                            <td>91.41</td>
                            <td>88.24</td>
                            <td>38.16</td>
                            <td>45.97 </td>
                        </tr>
                        <tr>
                            <td>ConvNeXt*</td>
                            <td>42.63</td>
                            <td>26.56</td>
                            <td>12.57</td>
                            <td>14.53</td>
                            <td>63.58</td>
                            <td>40.67</td>
                            <td>17.82</td>
                            <td>21.12</td>
                        </tr>
                        <tr>
                            <td>ConvNeXt</td>
                            <td>90.32</td>
                            <td><b>85.13</b></td>
                            <td>57.03</td>
                            <td>60.61</td>
                            <td><b>94.07</b></td>
                            <td>90.49</td>
                            <td>64.84</td>
                            <td>68.81</td>
                        </tr>
                        <tr>
                            <td>ConvNeXt + FL</td>
                            <td>88.28</td>
                            <td>82.02</td>
                            <td>51.22</td>
                            <td>55.16</td>
                            <td>87.60</td>
                            <td>81.11</td>
                            <td>22.22</td>
                            <td>31.37</td>
                        </tr>
                        <tr>
                            <td>ConvNeXt + CB</td>
                            <td><b>90.53</b></td>
                            <td>84.80</td>
                            <td><b>57.94</b></td>
                            <td><b>61.38</b></td>
                            <td>93.15</td>
                            <td><b>90.56</b></td>
                            <td><b>71.41</b></td>
                            <td><b>74.38</b></td>
                        </tr>
                        <tr>
                            <td>ConvNeXt + FL + CB</td>
                            <td>84.89</td>
                            <td>77.92</td>
                            <td>48.99</td>
                            <td>52.71</td>
                            <td>85.14</td>
                            <td>57.25</td>
                            <td>39.28</td>
                            <td>41.76</td>
                        </tr>
                    </table>
            </div>
            <br>
            <br>
        </div>
    </div>
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Analyses</h2>
                <div class="content has-text-justified">
                    <p>
                        The table above shows the fish classification results at the Family and Order levels. From the table, it is evident that larger models consistently outperform smaller models in terms of 
                        classification accuracy. Specifically, the best-performing ConvNeXt model achieved an average classification accuracy of 60.61% and 68.81% at the Family and Order levels, respectively. 
                        We also observed that the performance for rare classes was significantly worse than that for common classes, with an average classification accuracy of 57.03% and 64.84% at the Family and 
                        Order levels, respectively. This is because these rare classes have insufficient annotations, which poses great challenges for fish classification recognition.
                    </p>
                    <h3 class="title is-3">Mis-Classification</h3>
                    <p>
                        The top-performing ConvNeXt model exhibits an accuracy exceeding 80% across 38 out of 83 categories, while falling below 20% accuracy in 8 categories. 
                        The most prevalent error occurs when misclassifying species belonging to the Cyprinodontiformes, Dactylopteriformes, Osmeriformes, Elopiformes, and Gonorynchiformes orders as Ophidiiformes. 
                        Additionally, another common misclassification arises from misclassifying images from Eupercaria category as Elopiformes.
                        <img src="static/images/conf.png" alt="teaser" width="100%">
                    </p>
                    <!-- <h4 class="title is-3">Mis-Classified Examples</h3> -->
                    <!-- <p> -->
                        <!-- We show examples from Cyprinodontiformes, Dactylopteriformes, Osmeriformes, Elopiformes, and Gonorynchiformes orders as Ophidiiformes.  -->
                        <!-- Additionally, another common misclassification arises from misclassifying images from Eupercaria category as Elopiformes. -->
                    <!-- </p> -->
                </div>
            </div>
        </div>
    </div>
</section>



<section class="section hero is-light">
    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
            <h2 class="title is-3">Detection Results</h2>
            <!-- <h4 class="title is-5">Input: Neutral identity image + Audio</h4> -->
            <div style="text-align: center;">
                <table align="center" border="4px solid black" width="60%" min-width="300px" caption-side="left">
                    <caption>Fish detection performance on common, medium and rare classes at the Order and Family taxonomic levels.</caption>
                    <tr>
                        <th rowspan="2">Level</th>
                        <th rowspan="2">Method</th>
                        <th colspan="5">Commom/Medium/Rare</th>
                        <th colspan="5">Average Per Class</th>
                        </tr>
                        <tr>
                            <td >mAP50</td>
                            <td >mAP60</td>
                            <td >mAP70</td>
                            <td >mAP80</td>
                            <td >mAP90</td>
                            <td >mAP50</td>
                            <td >mAP60</td>
                            <td >mAP70</td>
                            <td >mAP80</td>
                            <td >mAP90</td>

                        </tr>
                        <tr>
                            <td rowspan="2">Order</td>
                            <td>YOLOF</td>
                            <td>77.3/65.2/39.2</td>
                            <td>72.7/62.1/38.0</td>
                            <td>61.6/53.4/34.7</td>
                            <td>38.8/34.9/25.4</td>
                            <td>11.7/9.6/11.8</td>
                            <td>45.0</td>
                            <td>43.4</td>
                            <td>39.3</td>
                            <td>27.8</td>
                            <td>11.7</td>
                        </tr>
                        <tr>
                            <td>TOOD</td>
                            <td>84.8/76.8/50.3</td>
                            <td>80.1/73.2/48.5</td>
                            <td>69.4/64.4/43.6</td>
                            <td>46.1/42.6/32.7</td>
                            <td>15.4/14.3/13.6</td>
                            <td>56.5</td>
                            <td>54.3</td>
                            <td>48.5</td>
                            <td>35.4</td>
                            <td>14.1</td>
                        </tr>
                        <tr>
                            <td rowspan="2">Family</td>
                            <td>YOLOF</td>
                            <td>67.2/53.1/27.1</td>
                            <td>64.0/50.4/26.6</td>
                            <td>54.9/43.3/24.4</td>
                            <td>35.5/27.3/18.8</td>
                            <td>9.9/7.9/7.7</td>
                            <td>30.6</td>
                            <td>29.8</td>
                            <td>26.9</td>
                            <td>20.0</td>
                            <td>7.8</td>
                        </tr>
                        <tr>
                            <td>TOOD</td>
                            <td>81.1/64.0/22.5</td>
                            <td>77.1/60.1/21.9</td>
                            <td>66.5/51.2/20.1</td>
                            <td>44.0/32.8/15.7</td>
                            <td>14.5/10.9/7.7</td>
                            <td>27.9</td>
                            <td>26.9</td>
                            <td>24.2</td>
                            <td>18.0</td>
                            <td>8.2</td>
                        </tr>
                    </table>
            </div>
            <br>
            <br>
        </div>
    </div>
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Functional Trait prediction Results</h2>
                <div class="content has-text-justified">
                    <p>
                        The aboev table shows the fish detection results at both the Family and Order levels. From the table, it is evident that TOOD consistently outperforms YOLOF in all metrics for Order level detection. 
                        However, we observe that for family level classification, YOLOF exhibited better performance for Rare classes. Given the significantly higher number of Rare classes (405) as compared to Medium (52) and 
                        Common (6) classes, it is not surprising that the average Mean Average Precision (MAP) per class was lower for TOOD.
                        Therefore, we note that the evaluation of model performance can be influenced by the prevalence of different classes in the dataset.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>



<br>
<section class="hero teaser">
    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
            <h2 class="title is-3">Functional Traits Results</h2>
            <!-- <h4 class="title is-5">Input: Neutral identity image + Audio</h4> -->
            <div style="text-align: center;">
                <table align="center" border="4px solid black" width="60%" min-width="300px" caption-side="left">
                    <caption>Habitat Classification performance in supervised and zero-shot settings.</caption>
                    <tr>
                        <th rowspan="2">Backbone</th>
                        <th colspan="2">Seen (%)</th>
                        <th colspan="2">Unseen (%)</th>
                        </tr>
                        <tr>
                            <td >F1/Acc.</td>
                            <td >Acc-All</td>
                            <td >F1/Acc.</td>
                            <td >Acc-All</td>
                        </tr>
                        <tr>
                            <td>ResNet-34</td>
                            <td>74.83 / 87.20</td>
                            <td>40.04</td>
                            <td>54.38 / 78.48</td>
                            <td>15.84</td>
                        </tr>
                        <tr>
                            <td>ResNet-50</td>
                            <td>71.80 / 84.52</td>
                            <td>30.85</td>
                            <td>53.52 / 76.71</td>
                            <td>13.92</td>
                        </tr>
                        <tr>
                            <td>ResNet-101</td>
                            <td>73.80 / 85.67</td>
                            <td>34.45</td>
                            <td>54.37 / 77.47</td>
                            <td>15.12</td>
                        </tr>
                        <tr>
                            <td>ViT-S</td>
                            <td>75.25 / 86.86</td>
                            <td>38.62</td>
                            <td>54.62 / 78.99</td>
                            <td>16.94 </td>
                        </tr>
                        <tr>
                            <td>ViT-B</td>
                            <td>78.65 / 88.94</td>
                            <td>46.91</td>
                            <td>55.72 / 79.93</td>
                            <td>18.44</td>
                        </tr>
                        <tr>
                            <td>ViT-L</td>
                            <td>81.72 / 90.45</td>
                            <td>54.00</td>
                            <td>55.94 / 80.23</td>
                            <td>18.80</td>
                        </tr>
                        <tr>
                            <td>BeiT</td>
                            <td>78.15 / 88.93</td>
                            <td>49.97</td>
                            <td>54.60 / 78.82</td>
                            <td>17.26</td>
                        </tr>
                        <tr>
                            <td>ConvNeXt</td>
                            <td>83.30 / 91.03</td>
                            <td>54.80</td>
                            <td>56.34 / 79.50</td>
                            <td>18.00</td>
                        </tr>
                    </table>
            </div>
            <br>
            <br>
        </div>
    </div>
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Functional Trait prediction Results</h2>
                <div class="content has-text-justified">
                    <p>
                        The table above shows the classification results for nine fish functional traits. Overall, the larger models outperformed the smaller ones. Specifically, the ConvNeXt model achieved the best 
                        results with an average f1-score of 81.72% and a classification accuracy of 90.45%. We also report the classification accuracy when our model correctly predicts all nine functional traits 
                        simultaneously, marked as ``Acc-all". It was surprising that the best-performing ConvNeXt model obtained an accuracy-all of 54.0% for correctly predicting all classes simultaneously. 
                        Please refer to the paper for examples and a detailed breakdown of the per-trait classification performance.
                    </p>
                    <h3 class="title is-3">Zero-Shot Classification</h3>
                    <p>
                        We further evaluated the habitat classification performance in a zero-shot setting, where we evaluated habitat classification on unseen classes, which were not never seen during training. 
                        To achieve this, we trained the ConvNeXt model on 58 common and medium classes (according to their family classes) and evaluated the performance on 405 rare classes. 
                        Although zero-shot habitat classification performance is worse than the supervised setting, the best-performed ViT-L model still shows a reasonable performance for zero-shot habitat classification, 
                        with a classification accuracy of 80.23% and 18.80% on accuracy and accuracy-all. This demonstration showcases the capacity of the deep learning model to predict the functional traits of previously 
                        unseen species, thereby establishing a valuable tool to help assigning the functional traits during the discovery of new species.                    </p>
                </div>
            </div>
        </div>
    </div>
</section>

<br>
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Conclusion</h2>
                <div class="content has-text-justified">
                    <p>
                        This work presents FishNet, a large-scale diverse dataset consisting of 94,532 images from 17,357 species organized based on the scientific classification of aquatic species. 
                        The dataset is accompanied by 114,375 manually labeled bounding box annotations and 22 functional traits information. Furthermore, we establish three benchmarks, namely fish classification, 
                        fish detection, and functional traits prediction, to facilitate the advancement of aquatic species recognition and promote further research in the field of aquatic ecology. 
                        The experimental results demonstrate that accurate fish recognition and functional traits prediction are still challenging due to several factors, such as large species diversity, diverse backgrounds, 
                        low contrast, etc. 

                        We will release our data and associated code to encourage further research in developing more accurate and effective tools for monitoring and protecting aquatic ecosystems. 
                        Our FishNet dataset will also encourage research into evaluating the impact of climate change on aquatic ecosystems and identifying potential solutions to help maintain the health and resilience 
                        of aquatic ecosystems and contribute to mitigating the impacts of climate change.

                    </p>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End paper results -->

<!-- Paper Analyses -->
<!-- <section class="section hero is-light">
     <div class="container is-max-desktop"> 
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Analyses</h2>
                <h2 class="title is-3">Misclassifications</h2>
                <div class="content has-text-justified">
                    <p>
                        Discuss abut the misclassifications using confusion matrix. and see the relation when going to fine grained classifications 
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>  -->




<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">

                    <p>
                        This page was built using the <a
                            href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic
                        Project Page Template</a>.
                        You are free to borrow the of this website, we just ask that you link back to this page in the
                        footer. <br> This website is licensed under a <a rel="license"
                                                                         href="http://creativecommons.org/licenses/by-sa/4.0/"
                                                                         target="_blank">Creative
                        Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p>

                </div>
            </div>
        </div>
    </div>
</footer>

<!-- Statcounter tracking code -->

<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

<!-- End of Statcounter Code -->

</body>
</html>
